{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww12680\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 HOW TO RUN THE PROGRAM
\b0 \
\
There are four .py file in the folder. The program runs on Python 2, and numpy, scipy and matplotlib needed to be installed before running the program.\
\
If you have any questions, feel free to shoot Baxi (bchong@andrew.cmu.edu) or Yunjin me (yunjinw@andrew.cmu.edu) an email. Have fun :)\
\

\b - runSimulator.py
\b0   The 
\b driver
\b0  runs the salamander simulator. The driver runs as:\
\
runSimulator(dutyFactor= ______,\
            	 interPhi=______, meterPhi=______, outerPhi=______,\
             	 a2=______, b2=______,\
             	 c1 = _____, c2 = _____, c3 = _____, c4 = _____,\
             	 printResult = True # Can set it to be False if don\'92t want the program prints results)\
\
Set the parameters (marked as blank) and simply run the simulator. It will print the results.\
\

\b - policyGradientRL.py
\b0  The 
\b driver
\b0  for training the policy gradient reinforcement learning model. The driver runs as:\
\
policyGradientTrain(t=30,  		  	# Number of perturbations\
			episodes=30,   	# Number of training episodes\
			epsilon=0.001, 	# The amplitude of policy perturbation\
			selfInit = True, 	# Use the selfInit function to train from hand-tuned parameters \
			object = 'AngleChange', 	# No need to change\
			stepSize = 0.5, 		# Step size for updating parameters\
			paramScaler = 7)		# No need to change\
\

\b -computeBodyVelocity.py   &   gm_Simulator.py
\b0 \
The salamander simulator.\
}